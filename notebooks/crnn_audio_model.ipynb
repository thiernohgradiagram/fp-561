{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edb238a",
   "metadata": {},
   "source": [
    "# BirdCLEF+ 2025: CRNN Audio Model\n",
    "This notebook implements the Convolutional Recurrent Neural Network (CRNN) for the BirdCLEF+ 2025 competition, by using a pretrained CNN model from `cnn_mel_spectrogram.ipynb` and adding a recurrent layer to capture temporal dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe60522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "\n",
    "# Define paths for Colab\n",
    "DATA_PATH = '/content/drive/MyDrive/birdclef-2025-data'\n",
    "MODEL_SAVE_DIR = '/content/drive/MyDrive/fp-561-models'\n",
    "CNN_MODEL_PATH = '/content/drive/MyDrive/fp-561-models/cnn_model.pth'  # Path to saved CNN model\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q librosa torchlibrosa timm torchaudio\n",
    "\n",
    "# Imports\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility and device setup\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed()\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14234bf8",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Load training metadata and define paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data path\n",
    "print(f'Data path exists: {os.path.exists(DATA_PATH)}')\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print('Please check that you have uploaded the birdclef-2025-data folder to your Google Drive')\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "print(f'Training samples: {len(train_df)}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8f7878",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Define mel-spectrogram extraction functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_melspec(audio, sr=32000, n_mels=128, fmin=20, fmax=16000, n_fft=1024, hop_length=512):\n",
    "    \"\"\"Compute and normalize mel-spectrogram\"\"\"\n",
    "    S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, fmin=fmin, fmax=fmax, n_fft=n_fft, hop_length=hop_length, power=2.0)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    norm = (S_db - S_db.min()) / (S_db.max() - S_db.min() + 1e-6)\n",
    "    return norm\n",
    "\n",
    "def audio_to_melspec(audio, sr=32000, duration=5):\n",
    "    \"\"\"Convert audio to fixed-length mel-spectrogram\"\"\"\n",
    "    target_len = int(sr * duration)\n",
    "    if len(audio) > target_len:\n",
    "        # Random crop if audio is longer than target\n",
    "        start = np.random.randint(0, len(audio)-target_len)\n",
    "        audio = audio[start:start+target_len]\n",
    "    else:\n",
    "        # Pad with zeros if audio is shorter than target\n",
    "        pad = target_len - len(audio)\n",
    "        audio = np.pad(audio, (pad//2, pad-pad//2))\n",
    "    melspec = compute_melspec(audio, sr=sr)\n",
    "    return melspec[np.newaxis, :, :]  # add channel dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55a077",
   "metadata": {},
   "source": [
    "## Audio Augmentation\n",
    "Define augmentation functions for better generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72956d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(audio, shift_factor=0.2):\n",
    "    \"\"\"Apply random time shift to audio\"\"\"\n",
    "    shift = int(len(audio) * shift_factor)\n",
    "    direction = np.random.randint(0, 2)\n",
    "    if direction == 1:\n",
    "        shift = -shift\n",
    "    aug_audio = np.roll(audio, shift)\n",
    "    # Set the rolled part to zero\n",
    "    if shift > 0:\n",
    "        aug_audio[:shift] = 0\n",
    "    else:\n",
    "        aug_audio[shift:] = 0\n",
    "    return aug_audio\n",
    "\n",
    "def add_noise(audio, noise_factor=0.01):\n",
    "    \"\"\"Add random Gaussian noise to audio\"\"\"\n",
    "    noise = np.random.normal(0, audio.std() * noise_factor, audio.shape)\n",
    "    return audio + noise\n",
    "\n",
    "def pitch_shift(audio, sr, pitch_factor=2):\n",
    "    \"\"\"Change pitch of audio without changing tempo\"\"\"\n",
    "    pitch_change = np.random.randint(-pitch_factor, pitch_factor)\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=pitch_change)\n",
    "\n",
    "def apply_augmentation(audio, sr=32000):\n",
    "    \"\"\"Apply a random combination of augmentations\"\"\"\n",
    "    # List of possible augmentations\n",
    "    augmentations = [\n",
    "        lambda x: time_shift(x),\n",
    "        lambda x: add_noise(x),\n",
    "        lambda x: pitch_shift(x, sr),\n",
    "        lambda x: x  # No augmentation\n",
    "    ]\n",
    "    \n",
    "    # Randomly select number of augmentations to apply\n",
    "    n_augments = np.random.randint(0, 3)  # 0, 1, or 2 augmentations\n",
    "    aug_indices = np.random.choice(len(augmentations), size=n_augments, replace=False)\n",
    "    \n",
    "    # Apply selected augmentations\n",
    "    result = audio\n",
    "    for idx in aug_indices:\n",
    "        result = augmentations[idx](result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6d57f",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "Define PyTorch dataset for CRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNNDataset(Dataset):\n",
    "    def __init__(self, df, path, sr=32000, duration=5, augment=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.path = path\n",
    "        self.sr = sr\n",
    "        self.duration = duration\n",
    "        self.augment = augment\n",
    "        self.labels = sorted(df['primary_label'].unique())\n",
    "        self.label2idx = {l:i for i,l in enumerate(self.labels)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Get file path and load audio\n",
    "        row = self.df.iloc[i]\n",
    "        audio, _ = sf.read(os.path.join(self.path, 'train_audio', row.filename))\n",
    "        \n",
    "        # Apply augmentation if enabled\n",
    "        if self.augment:\n",
    "            audio = apply_augmentation(audio, self.sr)\n",
    "        \n",
    "        # Convert to mel-spectrogram\n",
    "        melspec = audio_to_melspec(audio, sr=self.sr, duration=self.duration)\n",
    "        \n",
    "        # Get label index\n",
    "        label = self.label2idx[row.primary_label]\n",
    "        \n",
    "        return torch.tensor(melspec, dtype=torch.float32), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0389bf",
   "metadata": {},
   "source": [
    "## CRNN Model Definition Using Pretrained CNN\n",
    "Define a new CRNN architecture that uses the pretrained CNN as a feature extractor and adds a GRU layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db614850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extractor based on the pre-trained CNN model\"\"\"\n",
    "    def __init__(self, cnn_model_info):\n",
    "        super().__init__()\n",
    "        self.model_type = cnn_model_info.get('model_type', 'unknown')\n",
    "        \n",
    "        # Import the CNN model architecture from the cnn_mel_spectrogram notebook\n",
    "        # This is a simplified version - adjust based on actual CNN architecture\n",
    "        if 'backbone' in cnn_model_info and cnn_model_info['backbone']:\n",
    "            # It's a pretrained model using timm\n",
    "            import timm\n",
    "            backbone = cnn_model_info['backbone']\n",
    "            self.cnn = timm.create_model(\n",
    "                backbone,\n",
    "                pretrained=False,\n",
    "                in_chans=1,  # Single channel for grayscale mel-spectrogram\n",
    "                num_classes=0  # No classification head\n",
    "            )\n",
    "            \n",
    "            # Handle specific architecture types\n",
    "            if 'efficientnet' in backbone:\n",
    "                self.feature_dim = self.cnn.num_features\n",
    "            elif 'resnet' in backbone:\n",
    "                self.feature_dim = self.cnn.fc.in_features\n",
    "                self.cnn.fc = nn.Identity()\n",
    "            else:\n",
    "                # Default assumption\n",
    "                self.feature_dim = 512\n",
    "        else:\n",
    "            # Assume it's a custom CNN architecture\n",
    "            self.cnn = nn.Sequential(\n",
    "                nn.Conv2d(1, 32, kernel_size=3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "                nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "                nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
    "                nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2),\n",
    "                nn.AdaptiveAvgPool2d(1),  # Global average pooling\n",
    "                nn.Flatten()\n",
    "            )\n",
    "            self.feature_dim = 256\n",
    "        \n",
    "        # Load the pretrained weights\n",
    "        try:\n",
    "            # Try to load the CNN part only (exclude classifier weights if needed)\n",
    "            model_state = cnn_model_info['model_state']\n",
    "            \n",
    "            # Filter out classifier weights if present\n",
    "            cnn_state_dict = {k: v for k, v in model_state.items() \n",
    "                             if not k.startswith('classifier') and not k.startswith('fc')}\n",
    "            \n",
    "            # Load the weights into the CNN part\n",
    "            missing, unexpected = self.cnn.load_state_dict(cnn_state_dict, strict=False)\n",
    "            print(f\"Loaded CNN weights: {len(cnn_state_dict)} parameters\")\n",
    "            print(f\"Missing: {len(missing)}, Unexpected: {len(unexpected)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading CNN weights: {e}\")\n",
    "            print(\"Continuing with randomly initialized weights\")\n",
    "        \n",
    "        print(f\"CNN Feature extractor initialized with feature dimension: {self.feature_dim}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn(x)  # B, feature_dim\n",
    "        return features\n",
    "\n",
    "\n",
    "class CNNGRUModel(nn.Module):\n",
    "    \"\"\"CRNN model using pretrained CNN with GRU layer added\"\"\"\n",
    "    def __init__(self, cnn_model_info, num_classes, gru_hidden_size=256, freeze_cnn=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN feature extractor from pretrained model\n",
    "        self.cnn = CNNFeatureExtractor(cnn_model_info)\n",
    "        \n",
    "        # Freeze CNN weights if required\n",
    "        if freeze_cnn:\n",
    "            for param in self.cnn.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"CNN weights frozen\")\n",
    "        \n",
    "        # GRU layer\n",
    "        self.gru_hidden_size = gru_hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.cnn.feature_dim,\n",
    "            hidden_size=gru_hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            num_layers=2,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(gru_hidden_size * 2, num_classes)  # *2 for bidirectional\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # We need time slices for GRU\n",
    "        # Split spectrogram into overlapping windows along time dimension\n",
    "        # Assuming x shape: [batch_size, 1, freq_bins, time_steps]\n",
    "        time_slices = []\n",
    "        window_size = 16\n",
    "        stride = 8\n",
    "        \n",
    "        if x.size(3) < window_size:  # Handle short spectrograms\n",
    "            # Pass the whole spectrogram through CNN\n",
    "            features = self.cnn(x)  # [batch_size, feature_dim]\n",
    "            # Add time dimension\n",
    "            features = features.unsqueeze(1)  # [batch_size, 1, feature_dim]\n",
    "        else:\n",
    "            # Split into time windows and extract features from each\n",
    "            features_list = []\n",
    "            \n",
    "            for i in range(0, x.size(3) - window_size + 1, stride):\n",
    "                # Extract window\n",
    "                window = x[:, :, :, i:i+window_size]  # [batch_size, 1, freq_bins, window_size]\n",
    "                # Extract features from this window\n",
    "                feat = self.cnn(window)  # [batch_size, feature_dim]\n",
    "                features_list.append(feat)\n",
    "            \n",
    "            # Stack along time dimension\n",
    "            if features_list:\n",
    "                features = torch.stack(features_list, dim=1)  # [batch_size, num_windows, feature_dim]\n",
    "            else:\n",
    "                # Fallback for very short spectrograms\n",
    "                features = self.cnn(x).unsqueeze(1)  # [batch_size, 1, feature_dim]\n",
    "        \n",
    "        # Apply GRU to the sequence of CNN features\n",
    "        gru_out, _ = self.gru(features)  # [batch_size, seq_len, 2*hidden_size]\n",
    "        \n",
    "        # Use the final output for classification\n",
    "        out = gru_out[:, -1, :]  # [batch_size, 2*hidden_size]\n",
    "        out = self.dropout(out)\n",
    "        logits = self.classifier(out)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b6a495",
   "metadata": {},
   "source": [
    "## Loading the Pretrained CNN Model\n",
    "Load the CNN model that was trained on mel spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_cnn():\n",
    "    \"\"\"Load the pretrained CNN model from the saved file\"\"\"\n",
    "    if not os.path.exists(CNN_MODEL_PATH):\n",
    "        print(f\"Error: CNN model not found at {CNN_MODEL_PATH}\")\n",
    "        print(\"Please check that you have trained and saved the CNN model from cnn_mel_spectrogram.ipynb\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load the model info\n",
    "        cnn_model_info = torch.load(CNN_MODEL_PATH, map_location=DEVICE)\n",
    "        print(f\"Loaded CNN model info from {CNN_MODEL_PATH}\")\n",
    "        \n",
    "        # Check what type of model info we have\n",
    "        if isinstance(cnn_model_info, dict) and 'model_state' in cnn_model_info:\n",
    "            # This is the standardized format with metadata\n",
    "            print(f\"Model type: {cnn_model_info.get('model_type', 'unknown')}\")\n",
    "            model_state = cnn_model_info['model_state']\n",
    "            label_mapping = cnn_model_info.get('label_mapping', None)\n",
    "            \n",
    "            # Additional useful info if available\n",
    "            if 'input_params' in cnn_model_info:\n",
    "                print(f\"Input parameters: {cnn_model_info['input_params']}\")\n",
    "            if 'backbone' in cnn_model_info and cnn_model_info['backbone']:\n",
    "                print(f\"Backbone: {cnn_model_info['backbone']}\")\n",
    "                \n",
    "            return cnn_model_info\n",
    "                \n",
    "        elif isinstance(cnn_model_info, dict) and 'model_state_dict' in cnn_model_info:\n",
    "            # This is a checkpoint format with state_dict\n",
    "            print(\"Loaded model in checkpoint format\")\n",
    "            model_state = cnn_model_info['model_state_dict']\n",
    "            label_mapping = cnn_model_info.get('label_mapping', None)\n",
    "            \n",
    "            # Create a standardized format\n",
    "            return {\n",
    "                'model_state': model_state,\n",
    "                'label_mapping': label_mapping\n",
    "            }\n",
    "            \n",
    "        elif isinstance(cnn_model_info, dict) and any(k.endswith('.weight') for k in cnn_model_info.keys()):\n",
    "            # This is a raw state_dict\n",
    "            print(\"Loaded raw model state dict\")\n",
    "            return {\n",
    "                'model_state': cnn_model_info,\n",
    "                'label_mapping': None\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            print(\"Unknown model format. Attempting to use as state dict...\")\n",
    "            return {\n",
    "                'model_state': cnn_model_info,\n",
    "                'label_mapping': None\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CNN model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the CNN model\n",
    "cnn_model_info = load_pretrained_cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1d6a6",
   "metadata": {},
   "source": [
    "## Training and Validation\n",
    "Define training and validation loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ed7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for x, y in tqdm(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += predicted.eq(y).sum().item()\n",
    "    \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            # Update statistics\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "            \n",
    "            # Store outputs and targets for AUC calculation\n",
    "            all_outputs.append(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "            all_targets.append(F.one_hot(y, num_classes=outputs.size(1)).cpu().numpy())\n",
    "    \n",
    "    # Concatenate all outputs and targets\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "    # Calculate ROC-AUC (which is also the competition metric)\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    pos = (all_targets.sum(0) > 0)  # Classes with positive examples\n",
    "    auc = roc_auc_score(all_targets[:, pos], all_outputs[:, pos], average='macro')\n",
    "    \n",
    "    return running_loss / total, correct / total, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36882de2",
   "metadata": {},
   "source": [
    "## Main Training Routine\n",
    "Prepare loaders, model, and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9592c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(freeze_cnn=True):\n",
    "    # Prepare data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    tr, va = train_test_split(train_df, test_size=0.2, stratify=train_df.primary_label, random_state=42)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_ds = CRNNDataset(tr, DATA_PATH, augment=True)\n",
    "    val_ds = CRNNDataset(va, DATA_PATH, augment=False)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64, num_workers=2)\n",
    "    \n",
    "    # Number of classes\n",
    "    num_classes = len(train_ds.labels)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Use our pretrained CNN + GRU model\n",
    "    model = CNNGRUModel(\n",
    "        cnn_model_info=cnn_model_info,\n",
    "        num_classes=num_classes,\n",
    "        gru_hidden_size=256,\n",
    "        freeze_cnn=freeze_cnn\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    model_name = \"crnn_with_pretrained_cnn\"\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer - different learning rates for different parts\n",
    "    if freeze_cnn:\n",
    "        # Don't include CNN parameters in optimizer\n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': model.gru.parameters(), 'lr': 3e-4},\n",
    "            {'params': model.classifier.parameters(), 'lr': 3e-4}\n",
    "        ], weight_decay=1e-4)\n",
    "    else:\n",
    "        # Include CNN parameters with lower learning rate\n",
    "        optimizer = optim.AdamW([\n",
    "            {'params': model.cnn.parameters(), 'lr': 5e-5},  # Lower LR for CNN\n",
    "            {'params': model.gru.parameters(), 'lr': 3e-4},  # Higher LR for GRU\n",
    "            {'params': model.classifier.parameters(), 'lr': 3e-4}  # Higher LR for classifier\n",
    "        ], weight_decay=1e-4)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Training parameters\n",
    "    best_auc = 0\n",
    "    patience = 5\n",
    "    wait = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_auc': []}\n",
    "    best_model_path = os.path.join(MODEL_SAVE_DIR, f\"{model_name}_best.pt\")\n",
    "    \n",
    "    # Save label mapping for later use\n",
    "    label_mapping = train_ds.label2idx\n",
    "    torch.save(label_mapping, os.path.join(MODEL_SAVE_DIR, f\"{model_name}_label_mapping.pt\"))\n",
    "    print(f\"Saved label mapping with {len(label_mapping)} classes\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(20):\n",
    "        print(f\"\\nEpoch {epoch+1}/20\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, val_auc = validate(model, val_loader, criterion, DEVICE)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        # Print results\n",
    "        print(f'Epoch {epoch+1}: train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, val_auc={val_auc:.4f}')\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_auc'].append(val_auc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_auc': val_auc,\n",
    "                'label_mapping': train_ds.label2idx\n",
    "            }, best_model_path)\n",
    "            wait = 0\n",
    "            print(f\"New best model with val_auc={val_auc:.4f}\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"Training complete. Best validation AUC: {best_auc:.4f} at epoch {checkpoint['epoch']+1}\")\n",
    "    \n",
    "    # Save final model in a format suitable for ensemble\n",
    "    torch.save({\n",
    "        'model_state': model.state_dict(),\n",
    "        'label_mapping': label_mapping,\n",
    "        'model_type': 'crnn_with_pretrained_cnn',\n",
    "        'input_params': {\n",
    "            'sr': 32000,\n",
    "            'n_mels': 128,\n",
    "            'fmin': 20,\n",
    "            'fmax': 16000,\n",
    "            'n_fft': 1024,\n",
    "            'hop_length': 512,\n",
    "            'duration': 5\n",
    "        },\n",
    "        'history': history\n",
    "    }, os.path.join(MODEL_SAVE_DIR, f\"{model_name}_ensemble.pth\"))\n",
    "    \n",
    "    print(f\"Model saved for ensemble use at '{os.path.join(MODEL_SAVE_DIR, f'{model_name}_ensemble.pth')}\")\n",
    "    \n",
    "    return model, label_mapping, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbbaf3",
   "metadata": {},
   "source": [
    "## Run Training\n",
    "Execute the training process with the pretrained CNN + GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose whether to freeze the CNN weights\n",
    "FREEZE_CNN = True  # Set to False to fine-tune the CNN as well\n",
    "\n",
    "# Train model\n",
    "model, label_mapping, history = main(freeze_cnn=FREEZE_CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ea4b5",
   "metadata": {},
   "source": [
    "## Visualize Training Results\n",
    "Plot training and validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history['train_acc'], label='Train')\n",
    "    plt.plot(history['val_acc'], label='Validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation AUC\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history['val_auc'], label='Validation')\n",
    "    plt.title('ROC AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a395a",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate the model on the validation set with more detailed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a120b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, dataset, device):\n",
    "    loader = DataLoader(dataset, batch_size=64, num_workers=2)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader):\n",
    "            x = x.to(device)\n",
    "            outputs = model(x)\n",
    "            preds = outputs.argmax(1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(y.numpy())\n",
    "    \n",
    "    # Convert indices to class names\n",
    "    idx_to_label = {v: k for k, v in dataset.label2idx.items()}\n",
    "    class_names = [idx_to_label[i] for i in range(len(idx_to_label))]\n",
    "    \n",
    "    # Compute confusion matrix for a subset of classes (top 20 by frequency)\n",
    "    class_counts = np.bincount([l for l in all_labels if l < len(class_names)])\n",
    "    top_classes = np.argsort(class_counts)[-20:]  # Top 20 most frequent classes\n",
    "    \n",
    "    # Filter predictions and labels for top classes only\n",
    "    mask = np.isin(all_labels, top_classes)\n",
    "    filtered_preds = [all_preds[i] for i, m in enumerate(mask) if m]\n",
    "    filtered_labels = [all_labels[i] for i, m in enumerate(mask) if m]\n",
    "    \n",
    "    # Compute and plot confusion matrix\n",
    "    cm = confusion_matrix(filtered_labels, filtered_preds)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[class_names[i] for i in top_classes],\n",
    "                yticklabels=[class_names[i] for i in top_classes])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Top 20 Classes)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    report = classification_report(\n",
    "        all_labels, all_preds, \n",
    "        target_names=[idx_to_label[i] for i in range(len(idx_to_label))],\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # Display top and bottom performing classes\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    top_performing = df_report.sort_values(by='f1-score', ascending=False).head(10)\n",
    "    bottom_performing = df_report.sort_values(by='f1-score').head(10)\n",
    "    \n",
    "    print(\"Top 10 best predicted classes:\")\n",
    "    print(top_performing[['precision', 'recall', 'f1-score', 'support']])\n",
    "    \n",
    "    print(\"\\nBottom 10 worst predicted classes:\")\n",
    "    print(bottom_performing[['precision', 'recall', 'f1-score', 'support']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "_, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df.primary_label, random_state=42)\n",
    "val_dataset = CRNNDataset(val_df, DATA_PATH, augment=False)\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(model, val_dataset, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd2536",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've successfully implemented a CRNN model for the BirdCLEF+ 2025 competition using the already trained CNN model from `cnn_mel_spectrogram.ipynb` as a feature extractor and adding GRU layers on top. This approach:\n",
    "\n",
    "1. Leverages the feature extraction capabilities already learned by the CNN\n",
    "2. Adds recurrent layers to capture temporal dynamics in the audio\n",
    "3. Reduces training time by reusing the pretrained CNN\n",
    "4. Creates complementary model characteristics for better ensemble results\n",
    "\n",
    "The model has been saved in Google Drive and is ready to be used as part of an ensemble approach."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
