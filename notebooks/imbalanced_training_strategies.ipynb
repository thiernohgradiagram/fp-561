{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aa825a1e",
      "metadata": {
        "id": "aa825a1e"
      },
      "source": [
        "# Handling Imbalanced Data in BirdCLEF Classification\n",
        "\n",
        "This notebook implements various strategies to handle the imbalanced nature of the BirdCLEF dataset. The techniques include:\n",
        "1. Stratified K-Fold Cross-Validation (replacing train/validation/test split)\n",
        "2. Class-Weighted Loss Functions\n",
        "3. Focal Loss Implementation\n",
        "4. Oversampling with WeightedRandomSampler\n",
        "5. Enhanced Data Augmentation for Minority Classes\n",
        "6. Combined Training Pipeline integrating all strategies\n",
        "7. Model Ensemble from different folds for robust predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e955dbbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e955dbbb",
        "outputId": "152d64b1-f628-41d0-a386-42524e7d63e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8a248a50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a248a50",
        "outputId": "3b0947f8-94de-41b3-ee37-106b93d3d219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.amp import autocast, GradScaler  # Updated import path\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a08da6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure GPU memory utilization\n",
        "import torch\n",
        "\n",
        "# Check GPU information\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Total GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"Initial Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "    print(f\"Initial Memory Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
        "\n",
        "    # Configure PyTorch to use more GPU memory\n",
        "    torch.backends.cudnn.benchmark = True  # Use cudnn auto-tuner to find fastest algorithm\n",
        "    torch.backends.cudnn.enabled = True\n",
        "    \n",
        "    # More aggressive memory allocation\n",
        "    if hasattr(torch.cuda, 'empty_cache'):\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    # Allow TF32 precision on Ampere or newer GPUs (much faster with minimal precision loss)\n",
        "    if torch.cuda.get_device_capability()[0] >= 8:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "    \n",
        "    print(\"GPU configuration completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0da6abb5",
      "metadata": {
        "id": "0da6abb5"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "Load the dataset and check class distribution. In a real scenario, this would involve loading the audio files and extracting features (like mel spectrograms). For this example, we'll assume we have preprocessed features stored in a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e197401",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e197401",
        "outputId": "c1c16052-76d7-49c8-9885-e7ea5f437823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading precomputed features from /content/drive/MyDrive/bird_features_scratch_copy.npz...\n",
            "Successfully loaded precomputed features!\n",
            "Features shape: (190153, 1, 128, 256)\n",
            "Labels shape: (190153,)\n",
            "Number of unique classes: 206\n"
          ]
        }
      ],
      "source": [
        "# Define paths\n",
        "DATA_PATH = '/content/drive/MyDrive/birdclef-2025-data'  # Adjust paths as needed\n",
        "MODEL_SAVE_DIR = '/content/drive/MyDrive/birdclef-2025-models'\n",
        "PRECOMPUTED_FEATURES_PATH = \"/content/drive/MyDrive/bird_features_scratch_copy.npz\"\n",
        "\n",
        "def load_precomputed_features(local_path=PRECOMPUTED_FEATURES_PATH):\n",
        "    \"\"\"Load precomputed features from Google Drive.\"\"\"\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(local_path):\n",
        "        print(f\"ERROR: Precomputed features file not found at {local_path}\")\n",
        "        return None, None\n",
        "\n",
        "    # Load the features\n",
        "    print(f\"Loading precomputed features from {local_path}...\")\n",
        "    try:\n",
        "        data = np.load(local_path)\n",
        "        X = data['data']\n",
        "        y = data['labels']\n",
        "        print(f\"Successfully loaded precomputed features!\")\n",
        "        print(f\"Features shape: {X.shape}\")\n",
        "        print(f\"Labels shape: {y.shape}\")\n",
        "        print(f\"Number of unique classes: {len(np.unique(y))}\")\n",
        "        return X, y\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading precomputed features: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Load the precomputed features\n",
        "X, y = load_precomputed_features()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a52832d",
      "metadata": {
        "id": "1a52832d"
      },
      "source": [
        "## Class Distribution Analysis\n",
        "\n",
        "Analyze the imbalance in the class distribution to understand the scale of the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "91fe42c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "91fe42c8",
        "outputId": "fced3c1e-4f03-4c87-d259-c7fdf9eb4db2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of classes: 206\n",
            "Class with most samples: 6130 samples\n",
            "Class with fewest samples: 2 samples\n",
            "Imbalance ratio: 3065.00\n"
          ]
        }
      ],
      "source": [
        "# Count occurrences of each label\n",
        "unique_labels, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "# Visualize class distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(counts)), counts)\n",
        "plt.title('Class Distribution in Dataset')\n",
        "plt.xlabel('Class ID')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.yscale('log')  # Use log scale for better visibility with imbalanced data\n",
        "plt.show()\n",
        "\n",
        "# Print class distribution statistics\n",
        "print(f\"Total number of classes: {len(unique_labels)}\")\n",
        "print(f\"Class with most samples: {np.max(counts)} samples\")\n",
        "print(f\"Class with fewest samples: {np.min(counts)} samples\")\n",
        "print(f\"Imbalance ratio: {np.max(counts) / np.min(counts):.2f}\")\n",
        "\n",
        "# Handle classes with only one sample if any exist\n",
        "if np.any(counts == 1):\n",
        "    print(\"Handling classes with only one sample...\")\n",
        "    # Remove classes with only one sample\n",
        "    valid_indices = np.isin(y, np.where(counts >= 2)[0])\n",
        "    X = X[valid_indices]\n",
        "    y = y[valid_indices]\n",
        "    print(f\"Removed {np.sum(~valid_indices)} samples with singleton classes\")\n",
        "    print(f\"Remaining data shape: {X.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c46ff46",
      "metadata": {
        "id": "6c46ff46"
      },
      "source": [
        "## 1. Stratified K-Fold Cross-Validation\n",
        "\n",
        "Set up stratified k-fold cross-validation to ensure all classes are represented in both training and validation sets.\n",
        "Note: We'll adjust the number of folds to handle rare classes that have too few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "124f6785",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "124f6785",
        "outputId": "47d9080c-dc19-4590-a6ca-68fc28b57ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating 5 stratified folds...\n",
            "Fold 1:\n",
            "  Training samples: 152122\n",
            "  Validation samples: 38031\n",
            "  Training class count: 206\n",
            "  Validation class count: 204\n",
            "Fold 2:\n",
            "  Training samples: 152122\n",
            "  Validation samples: 38031\n",
            "  Training class count: 206\n",
            "  Validation class count: 205\n",
            "Fold 3:\n",
            "  Training samples: 152122\n",
            "  Validation samples: 38031\n",
            "  Training class count: 206\n",
            "  Validation class count: 204\n",
            "Fold 4:\n",
            "  Training samples: 152123\n",
            "  Validation samples: 38030\n",
            "  Training class count: 206\n",
            "  Validation class count: 204\n",
            "Fold 5:\n",
            "  Training samples: 152123\n",
            "  Validation samples: 38030\n",
            "  Training class count: 206\n",
            "  Validation class count: 204\n",
            "Warning: Fold 1 is missing 2 classes in validation set\n",
            "Warning: Fold 2 is missing 1 classes in validation set\n",
            "Warning: Fold 3 is missing 2 classes in validation set\n",
            "Warning: Fold 4 is missing 2 classes in validation set\n",
            "Warning: Fold 5 is missing 2 classes in validation set\n",
            "Some classes are missing in certain folds. This is expected with very rare classes.\n",
            "Your handling of class imbalance should address this issue.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define number of folds\n",
        "k_folds = 5\n",
        "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# For storing fold results\n",
        "fold_val_aucs = []\n",
        "fold_models = []\n",
        "\n",
        "# Verify fold distribution\n",
        "print(f\"Creating {k_folds} stratified folds...\")\n",
        "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    train_labels = y[train_idx]\n",
        "    val_labels = y[val_idx]\n",
        "    train_unique, train_counts = np.unique(train_labels, return_counts=True)\n",
        "    val_unique, val_counts = np.unique(val_labels, return_counts=True)\n",
        "\n",
        "    print(f\"Fold {fold_idx+1}:\")\n",
        "    print(f\"  Training samples: {len(train_idx)}\")\n",
        "    print(f\"  Validation samples: {len(val_idx)}\")\n",
        "    print(f\"  Training class count: {len(train_unique)}\")\n",
        "    print(f\"  Validation class count: {len(val_unique)}\")\n",
        "\n",
        "# After creating the folds, verify no classes are missing\n",
        "missing_classes_in_folds = False\n",
        "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    train_labels = y[train_idx]\n",
        "    val_labels = y[val_idx]\n",
        "\n",
        "    # Check for classes missing in training or validation sets\n",
        "    all_classes = set(np.unique(y))\n",
        "    train_classes = set(np.unique(train_labels))\n",
        "    val_classes = set(np.unique(val_labels))\n",
        "\n",
        "    missing_in_train = all_classes - train_classes\n",
        "    missing_in_val = all_classes - val_classes\n",
        "\n",
        "    if missing_in_train:\n",
        "        print(f\"Warning: Fold {fold_idx+1} is missing {len(missing_in_train)} classes in training set\")\n",
        "        missing_classes_in_folds = True\n",
        "\n",
        "    if missing_in_val:\n",
        "        print(f\"Warning: Fold {fold_idx+1} is missing {len(missing_in_val)} classes in validation set\")\n",
        "        missing_classes_in_folds = True\n",
        "\n",
        "if missing_classes_in_folds:\n",
        "    print(\"Some classes are missing in certain folds. This is expected with very rare classes.\")\n",
        "    print(\"Your handling of class imbalance should address this issue.\")\n",
        "\n",
        "# Create a function to get data loaders for a specific fold with weighted sampling\n",
        "def get_fold_loaders(fold_idx, batch_size=32, weighted_sampling=True):\n",
        "    \"\"\"Get training and validation loaders for a specific fold\"\"\"\n",
        "    train_idx, val_idx = list(skf.split(X, y))[fold_idx]\n",
        "\n",
        "    # Split data for this fold\n",
        "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
        "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
        "    X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
        "    y_val_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
        "\n",
        "    # Create sampler for balanced training if requested\n",
        "    train_sampler = None\n",
        "    shuffle = True\n",
        "\n",
        "    if weighted_sampling:\n",
        "        class_counts = np.bincount(y_train_fold)\n",
        "        weights = 1.0 / class_counts\n",
        "        sample_weights = weights[y_train_fold]\n",
        "        train_sampler = WeightedRandomSampler(\n",
        "            weights=sample_weights,\n",
        "            num_samples=len(sample_weights),\n",
        "            replacement=True\n",
        "        )\n",
        "        shuffle = False  # Don't shuffle when using sampler\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(X_train_tensor, y_train_tensor),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        sampler=train_sampler,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        TensorDataset(X_val_tensor, y_val_tensor),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, train_idx, val_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181b4b10",
      "metadata": {
        "id": "181b4b10"
      },
      "source": [
        "## 2. Class-Weighted Loss Functions\n",
        "\n",
        "Implement class weighting to give more importance to rare classes during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "110edcb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "110edcb5",
        "outputId": "92eefa0b-221e-4041-92f0-ec174d464c20"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created weighted loss function that gives higher importance to rare classes\n"
          ]
        }
      ],
      "source": [
        "# Calculate class weights inversely proportional to class frequencies\n",
        "class_weights = compute_class_weight('balanced', classes=unique_labels, y=y)\n",
        "\n",
        "# Convert to tensor for PyTorch\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "# Visualize the weights\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(class_weights)), class_weights)\n",
        "plt.title('Class Weights')\n",
        "plt.xlabel('Class ID')\n",
        "plt.ylabel('Weight')\n",
        "plt.show()\n",
        "\n",
        "# Create weighted loss function\n",
        "weighted_criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "print(\"Created weighted loss function that gives higher importance to rare classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e4ff036",
      "metadata": {
        "id": "5e4ff036"
      },
      "source": [
        "## 3. Focal Loss Implementation\n",
        "\n",
        "Focal Loss is designed to address class imbalance by down-weighting the loss assigned to well-classified examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5bba0588",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bba0588",
        "outputId": "f0587b50-9267-40d5-df6f-8dceb7a35e63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Focal Loss created with gamma=2.0 and class weighting\n"
          ]
        }
      ],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha  # Weight for each class\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-BCE_loss)  # pt is the probability of the true class\n",
        "        F_loss = (1-pt)**self.gamma * BCE_loss  # Apply focusing parameter\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Create focal loss with class weights\n",
        "focal_criterion = FocalLoss(gamma=2.0, alpha=class_weights_tensor)\n",
        "print(\"Focal Loss created with gamma=2.0 and class weighting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b805dc1",
      "metadata": {
        "id": "6b805dc1"
      },
      "source": [
        "## 4. Oversampling with WeightedRandomSampler\n",
        "\n",
        "Implement weighted random sampling to ensure equal representation of all classes during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2f806476",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f806476",
        "outputId": "a51482a3-4b7c-4690-cd44-60ef8093552f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WeightedRandomSampler function created for balanced batch sampling\n"
          ]
        }
      ],
      "source": [
        "def create_weighted_sampler(labels):\n",
        "    \"\"\"Create a weighted sampler to balance class distribution\"\"\"\n",
        "    # Calculate class counts\n",
        "    class_counts = np.bincount(labels)\n",
        "\n",
        "    # Compute sample weights (inverse of class frequency)\n",
        "    weights = 1.0 / class_counts\n",
        "    sample_weights = weights[labels]\n",
        "\n",
        "    # Create sampler with replacement to ensure all classes are equally represented\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True\n",
        "    )\n",
        "    return sampler\n",
        "\n",
        "# We'll use this function when creating DataLoaders in the training section\n",
        "print(\"WeightedRandomSampler function created for balanced batch sampling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8112b5fe",
      "metadata": {
        "id": "8112b5fe"
      },
      "source": [
        "## 5. Enhanced Data Augmentation for Minority Classes\n",
        "\n",
        "Create stronger augmentation for minority classes to generate more diverse training examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d48cc5e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d48cc5e1",
        "outputId": "54a2333d-1ee3-44d6-c7f9-59180c9b942f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created adaptive augmentation function that applies stronger augmentation to rare classes\n"
          ]
        }
      ],
      "source": [
        "# Implement SpecAugment for frequency and time masking\n",
        "class SpecAugment(nn.Module):\n",
        "    def __init__(self, freq_mask_param=10, time_mask_param=24, num_freq_masks=2, num_time_masks=2):\n",
        "        super(SpecAugment, self).__init__()\n",
        "        self.freq_mask_param = freq_mask_param\n",
        "        self.time_mask_param = time_mask_param\n",
        "        self.num_freq_masks = num_freq_masks\n",
        "        self.num_time_masks = num_time_masks\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, channels, freq, time]\n",
        "        device = x.device\n",
        "        batch_size = x.size(0)\n",
        "        spec_height = x.size(2)  # freq axis\n",
        "        spec_width = x.size(3)   # time axis\n",
        "\n",
        "        # Apply frequency masks\n",
        "        for _ in range(self.num_freq_masks):\n",
        "            for i in range(batch_size):\n",
        "                freq_mask_size = torch.randint(0, self.freq_mask_param, (1,))[0]\n",
        "                if freq_mask_size > 0:\n",
        "                    freq_start = torch.randint(0, spec_height - freq_mask_size, (1,))[0]\n",
        "                    x[i, :, freq_start:freq_start + freq_mask_size, :] = 0\n",
        "\n",
        "        # Apply time masks\n",
        "        for _ in range(self.num_time_masks):\n",
        "            for i in range(batch_size):\n",
        "                time_mask_size = torch.randint(0, self.time_mask_param, (1,))[0]\n",
        "                if time_mask_size > 0:\n",
        "                    time_start = torch.randint(0, spec_width - time_mask_size, (1,))[0]\n",
        "                    x[i, :, :, time_start:time_start + time_mask_size] = 0\n",
        "\n",
        "        return x\n",
        "\n",
        "def adaptive_spec_augment(spectrogram, label, class_counts, rare_threshold=10):\n",
        "    \"\"\"Apply stronger augmentation to rare classes and mild augmentation to common ones.\"\"\"\n",
        "    # Get class frequency\n",
        "    if label >= len(class_counts):\n",
        "        return spectrogram\n",
        "\n",
        "    class_count = class_counts[label]\n",
        "\n",
        "    # Apply stronger augmentation for rare classes\n",
        "    if (class_count < rare_threshold):\n",
        "        # For rare classes, use stronger frequency and time masking\n",
        "        # Create temporary SpecAugment with more aggressive parameters\n",
        "        aggressive_spec_augment = SpecAugment(\n",
        "            freq_mask_param=20,       # Wider frequency masks\n",
        "            time_mask_param=40,       # Wider time masks\n",
        "            num_freq_masks=3,         # More frequency masks\n",
        "            num_time_masks=3          # More time masks\n",
        "        )\n",
        "        return aggressive_spec_augment(spectrogram)\n",
        "    else:\n",
        "        # Use standard augmentation for common classes\n",
        "        standard_spec_augment = SpecAugment(\n",
        "            freq_mask_param=10,\n",
        "            time_mask_param=20,\n",
        "            num_freq_masks=2,\n",
        "            num_time_masks=2\n",
        "        )\n",
        "        return standard_spec_augment(spectrogram)\n",
        "\n",
        "print(\"Created adaptive augmentation function that applies stronger augmentation to rare classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1a6bd52",
      "metadata": {
        "id": "a1a6bd52"
      },
      "source": [
        "## Mixup Data Augmentation\n",
        "\n",
        "Implement mixup augmentation to improve robustness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c381679d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c381679d",
        "outputId": "3b9fb8d1-217a-4359-ff89-93073475a34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mixup augmentation ready to use with alpha=0.2\n"
          ]
        }
      ],
      "source": [
        "# Implement mixup data augmentation for training\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "# Mixup loss function\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "print(\"Mixup augmentation ready to use with alpha=0.2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c89b18",
      "metadata": {
        "id": "76c89b18"
      },
      "source": [
        "## Define a CNN Model\n",
        "\n",
        "Define a simple CNN model for the BirdCLEF classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "939eb4ae",
      "metadata": {
        "id": "939eb4ae"
      },
      "outputs": [],
      "source": [
        "class BirdCNN(nn.Module):\n",
        "    def __init__(self, input_channels=1, num_classes=None):\n",
        "        super(BirdCNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.4),\n",
        "        )\n",
        "\n",
        "        # Calculate size after convolutions (8x dense size for mel spectrograms 128x256)\n",
        "        self.feature_dims = 256 * 16 * 32  # Channels * Height * Width\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.feature_dims, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63c4e89",
      "metadata": {
        "id": "d63c4e89"
      },
      "source": [
        "## 6. Combined Approach: K-Fold Training with All Strategies\n",
        "\n",
        "Now we'll integrate all our strategies into a complete training pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5926b6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5926b6a",
        "outputId": "93f1bce1-738b-4e67-e611-0b234414d6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full training pipeline with imbalanced data strategies is ready to run.\n"
          ]
        }
      ],
      "source": [
        "# Combined training function for imbalanced data with optimized GPU memory usage\n",
        "def train_with_imbalanced_strategies(model_class, X, y, n_folds=5, num_epochs=50, patience=10):\n",
        "    \"\"\"Train with k-fold CV and all imbalanced data strategies with optimized GPU memory usage\"\"\"\n",
        "    # Limit folds to minimum samples in any class\n",
        "    unique_labels, counts = np.unique(y, return_counts=True)\n",
        "    min_samples = np.min(counts)\n",
        "    n_folds = min(n_folds, min_samples)\n",
        "    print(f\"Using {n_folds} folds (limited by minimum class samples of {min_samples})\")\n",
        "    \n",
        "    # Track results across folds\n",
        "    models = []\n",
        "    fold_val_aucs = []\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "    \n",
        "    # Setup stratified k-fold\n",
        "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "    \n",
        "    # Get class counts for adaptive augmentation\n",
        "    class_counts = np.bincount(y)\n",
        "    \n",
        "    # Configure mixed precision training - ALWAYS use this for optimal GPU memory usage\n",
        "    use_amp = torch.cuda.is_available()\n",
        "    scaler = GradScaler() if use_amp else None\n",
        "    \n",
        "    # Optimize CUDA performance\n",
        "    if use_amp:\n",
        "        # Set memory allocation strategy - aggressive for large models\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        # Print CUDA memory stats before training\n",
        "        print(f\"CUDA Memory before training: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated, \"\n",
        "              f\"{torch.cuda.memory_reserved() / 1e9:.2f} GB reserved\")\n",
        "    \n",
        "    # Determine optimal batch size based on available GPU memory (much larger)\n",
        "    total_gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0\n",
        "    print(f\"Total GPU Memory: {total_gpu_memory:.2f} GB\")\n",
        "    \n",
        "    # Scale batch size to maximize GPU usage - up to 70% of available memory\n",
        "    # For an 84GB GPU, this should allow ~60GB usage\n",
        "    batch_size = 1024  # Default large batch size\n",
        "    if total_gpu_memory > 40:  # If VRAM > 40GB\n",
        "        batch_size = 2048      # Use very large batch\n",
        "    if total_gpu_memory > 70:  # If VRAM > 70GB (like A100 80GB)\n",
        "        batch_size = 4096      # Use enormous batch size\n",
        "        \n",
        "    print(f\"Using batch size: {batch_size} for optimal GPU memory utilization\")\n",
        "    \n",
        "    # Loop through folds\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Training fold {fold+1}/{n_folds}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        \n",
        "        # Split data for this fold\n",
        "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
        "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
        "        \n",
        "        # Create tensors with optimized memory usage\n",
        "        X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
        "        y_train_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
        "        X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
        "        y_val_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
        "        \n",
        "        # Compute class weights for this fold\n",
        "        unique_classes = np.unique(y_train_fold)\n",
        "        class_weights = compute_class_weight('balanced', classes=unique_classes, y=y_train_fold)\n",
        "        \n",
        "        # Map weights to all possible classes\n",
        "        full_class_weights = np.ones(len(np.unique(y)), dtype=np.float32)\n",
        "        for i, cls in enumerate(unique_classes):\n",
        "            full_class_weights[cls] = class_weights[i]\n",
        "            \n",
        "        class_weights_tensor = torch.tensor(full_class_weights, dtype=torch.float32).to(device)\n",
        "        \n",
        "        # Create weighted sampler for this fold's training data\n",
        "        train_sampler = create_weighted_sampler(y_train_fold)\n",
        "        \n",
        "        # Create DataLoaders with much larger batch size and more workers\n",
        "        # This will significantly increase GPU memory usage\n",
        "        train_loader = DataLoader(\n",
        "            TensorDataset(X_train_tensor, y_train_tensor),\n",
        "            batch_size=batch_size,  # Use massive batch size based on available GPU memory\n",
        "            sampler=train_sampler,  # Use weighted sampler instead of shuffle\n",
        "            num_workers=32,         # Increased from 16 to 32\n",
        "            pin_memory=True,\n",
        "            prefetch_factor=4,      # Prefetch 4 batches\n",
        "            persistent_workers=True # Keep workers alive between iterations\n",
        "        )\n",
        "            \n",
        "        val_loader = DataLoader(\n",
        "            TensorDataset(X_val_tensor, y_val_tensor),\n",
        "            batch_size=batch_size,  # Use massive batch size\n",
        "            shuffle=False,\n",
        "            num_workers=32,         # Increased from 16 to 32\n",
        "            pin_memory=True,\n",
        "            prefetch_factor=4,      # Prefetch 4 batches\n",
        "            persistent_workers=True # Keep workers alive between iterations\n",
        "        )\n",
        "            \n",
        "        # Initialize model\n",
        "        num_classes = len(np.unique(y))\n",
        "        model = model_class(input_channels=1, num_classes=num_classes).to(device)\n",
        "        \n",
        "        # Use Focal Loss with class weighting\n",
        "        criterion = FocalLoss(gamma=2.0, alpha=class_weights_tensor)\n",
        "        \n",
        "        # Use higher learning rate with larger batch size\n",
        "        base_lr = 0.001\n",
        "        scaled_lr = base_lr * (batch_size / 256)  # Scale LR based on batch size\n",
        "        print(f\"Using scaled learning rate: {scaled_lr:.5f} (base: {base_lr})\")\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=scaled_lr, weight_decay=0.01)\n",
        "        \n",
        "        # Use aggressive learning rate scheduler\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
        "        )\n",
        "            \n",
        "        # Training loop for this fold\n",
        "        best_val_auc = 0.0\n",
        "        epochs_without_improvement = 0\n",
        "            \n",
        "        for epoch in range(num_epochs):\n",
        "            # Training phase\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "                \n",
        "            # Print GPU usage at the start of each epoch\n",
        "            if use_amp:\n",
        "                print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated, \"\n",
        "                      f\"{torch.cuda.memory_reserved() / 1e9:.2f} GB reserved\")\n",
        "                    \n",
        "            for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
        "                # Move data to GPU in non-blocking way\n",
        "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "                    \n",
        "                # Apply adaptive augmentation based on class rarity\n",
        "                for i in range(inputs.shape[0]):\n",
        "                    label = labels[i].item()\n",
        "                    inputs[i:i+1] = adaptive_spec_augment(inputs[i:i+1], label, class_counts)\n",
        "                        \n",
        "                # Apply mixup augmentation\n",
        "                inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=0.2)\n",
        "                    \n",
        "                # Zero gradients\n",
        "                optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
        "                    \n",
        "                # Forward pass with mixed precision\n",
        "                with autocast(enabled=use_amp, device_type='cuda'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "                        \n",
        "                # Backward and optimize with gradient scaling for mixed precision\n",
        "                if use_amp:\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                        \n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (lam * (predicted == targets_a).float() + (1 - lam) * (predicted == targets_b).float()).sum().item()\n",
        "                    \n",
        "            train_loss = running_loss / total\n",
        "            train_acc = 100 * correct / total\n",
        "                \n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            all_outputs = []\n",
        "            all_labels = []\n",
        "                \n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
        "                    inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "                        \n",
        "                    # Forward pass with mixed precision\n",
        "                    with autocast(enabled=use_amp, device_type='cuda'):\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                            \n",
        "                    # Statistics\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "                        \n",
        "                    # Store outputs and labels for ROC-AUC calculation\n",
        "                    all_outputs.append(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
        "                    all_labels.append(labels.cpu().numpy())\n",
        "                        \n",
        "            # Calculate validation metrics\n",
        "            val_loss = val_loss / val_total\n",
        "            val_acc = 100 * val_correct / val_total\n",
        "                \n",
        "            # Calculate ROC-AUC\n",
        "            all_outputs = np.concatenate(all_outputs)\n",
        "            all_labels = np.concatenate(all_labels)\n",
        "                \n",
        "            # One-hot encode labels for AUC calculation\n",
        "            encoder = OneHotEncoder(sparse_output=False, categories=[range(num_classes)])\n",
        "            labels_onehot = encoder.fit_transform(all_labels.reshape(-1, 1))\n",
        "                \n",
        "            # Calculate AUC only for present classes\n",
        "            col_sums = labels_onehot.sum(axis=0)\n",
        "            present_classes = np.where(col_sums > 0)[0]\n",
        "                \n",
        "            try:\n",
        "                val_auc = roc_auc_score(\n",
        "                    labels_onehot[:, present_classes],\n",
        "                    all_outputs[:, present_classes],\n",
        "                    multi_class='ovr',\n",
        "                    average='macro'\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating AUC: {e}\")\n",
        "                val_auc = 0.5  # Default value\n",
        "                    \n",
        "            print(f\"Fold {fold+1} - Epoch {epoch+1} - \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - \"\n",
        "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val AUC: {val_auc:.4f}\")\n",
        "                \n",
        "            # Print GPU memory utilization every epoch\n",
        "            if use_amp:\n",
        "                print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated, \"\n",
        "                      f\"{torch.cuda.memory_reserved() / 1e9:.2f} GB reserved\")\n",
        "                    \n",
        "            # Update learning rate based on validation AUC\n",
        "            scheduler.step(val_auc)\n",
        "                \n",
        "            # Check for improvement\n",
        "            if val_auc > best_val_auc:\n",
        "                best_val_auc = val_auc\n",
        "                epochs_without_improvement = 0\n",
        "                # Save best model for this fold\n",
        "                model_save_path = os.path.join(MODEL_SAVE_DIR, f\"bird_cnn_fold_{fold+1}.pt\")\n",
        "                torch.save(model.state_dict(), model_save_path)\n",
        "                print(f\"New best model for fold {fold+1} with Val AUC: {val_auc:.4f}\")\n",
        "            else:\n",
        "                epochs_without_improvement += 1\n",
        "                if epochs_without_improvement >= patience:\n",
        "                    print(f\"Early stopping on fold {fold+1} after {epoch+1} epochs\")\n",
        "                    break\n",
        "                    \n",
        "        # Free up memory between folds\n",
        "        if use_amp:\n",
        "            torch.cuda.empty_cache()\n",
        "                \n",
        "        # After training fold, load best model and evaluate on validation set\n",
        "        model_load_path = os.path.join(MODEL_SAVE_DIR, f\"bird_cnn_fold_{fold+1}.pt\")\n",
        "        model.load_state_dict(torch.load(model_load_path))\n",
        "        model.eval()\n",
        "                \n",
        "        # Get final predictions for this fold\n",
        "        fold_outputs = []\n",
        "        fold_labels = []\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(val_loader, desc=f\"Final evaluation of fold {fold+1}\"):\n",
        "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "                outputs = model(inputs)\n",
        "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "                fold_outputs.append(probs.cpu().numpy())\n",
        "                fold_labels.append(labels.cpu().numpy())\n",
        "                    \n",
        "        fold_outputs = np.concatenate(fold_outputs)\n",
        "        fold_labels = np.concatenate(fold_labels)\n",
        "                \n",
        "        # Store results\n",
        "        fold_val_aucs.append(best_val_auc)\n",
        "        all_predictions.append(fold_outputs)\n",
        "        all_true_labels.append(fold_labels)\n",
        "        models.append(model)\n",
        "                \n",
        "        print(f\"Completed fold {fold+1} with best AUC: {best_val_auc:.4f}\")\n",
        "                \n",
        "    # Calculate overall performance\n",
        "    mean_auc = np.mean(fold_val_aucs)\n",
        "    std_auc = np.std(fold_val_aucs)\n",
        "                \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Cross-validation completed:\")\n",
        "    print(f\"Mean ROC-AUC: {mean_auc:.4f} ± {std_auc:.4f}\")\n",
        "    print(f\"Fold AUCs: {fold_val_aucs}\")\n",
        "    print(f\"{'='*50}\")\n",
        "                \n",
        "    return {\n",
        "        'models': models,\n",
        "        'fold_aucs': fold_val_aucs,\n",
        "        'mean_auc': mean_auc,\n",
        "        'std_auc': std_auc,\n",
        "        'predictions': all_predictions,\n",
        "        'true_labels': all_true_labels\n",
        "    }\n",
        "                \n",
        "print(\"Full training pipeline with imbalanced data strategies is ready to run with enhanced GPU memory usage.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2843fe",
      "metadata": {
        "id": "8b2843fe"
      },
      "source": [
        "## 7. Run the Complete Training Pipeline\n",
        "\n",
        "Now we'll execute the full training pipeline with all our strategies for handling imbalanced data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bd27c5a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558,
          "referenced_widgets": [
            "f488547ff3c0495398050561ccc4607c",
            "584bfa84e4904340835484bac7bce695",
            "6447a8783ab7460ebda8084b711e85e2",
            "f7cb6328ad3b4198890e23d4917a8805",
            "be64467c866840e4948bc2aef9d37ecc",
            "c2df1701b30e4c2bb6b8f77ed9927604",
            "4c89465d58e64730beb21c964ce6ab16",
            "5a9a9089e4014f42b94242672f5863f4",
            "7b45332615cd4eb194216a31f0c00b32",
            "66b50f8a171b4e2eba1356c417d7bdf0",
            "2335072338ee45fdbb6c1d9206b2b616"
          ]
        },
        "id": "bd27c5a8",
        "outputId": "304d1305-6ff4-4524-db45-a62c04cb20d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 2 folds (limited by minimum class samples of 2)\n",
            "CUDA Memory before training: 0.00 GB allocated, 0.00 GB reserved\n",
            "\n",
            "==================================================\n",
            "Training fold 1/2\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f488547ff3c0495398050561ccc4607c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/30 [Train]:   0%|          | 0/372 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "autocast.__init__() missing 1 required positional argument: 'device_type'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6d7ed3eab90d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the full training pipeline with BirdCNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m cv_results = train_with_imbalanced_strategies(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBirdCNN\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Using the defined CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-8863e331c3ba>\u001b[0m in \u001b[0;36mtrain_with_imbalanced_strategies\u001b[0;34m(model_class, X, y, n_folds, num_epochs, patience)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;31m# Forward pass with mixed precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: autocast.__init__() missing 1 required positional argument: 'device_type'"
          ]
        }
      ],
      "source": [
        "# Run the full training pipeline with BirdCNN model\n",
        "cv_results = train_with_imbalanced_strategies(\n",
        "    model_class=BirdCNN,  # Using the defined CNN model\n",
        "    X=X,\n",
        "    y=y,\n",
        "    n_folds=5,\n",
        "    num_epochs=30,  # Adjust based on your computational resources\n",
        "    patience=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cca8c07f",
      "metadata": {
        "id": "cca8c07f"
      },
      "source": [
        "## 8. Ensemble Models from Different Folds\n",
        "\n",
        "Create an ensemble of models from different folds for better predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d633b29e",
      "metadata": {
        "id": "d633b29e"
      },
      "outputs": [],
      "source": [
        "# Create an ensemble prediction function\n",
        "def ensemble_predict(models, X_test):\n",
        "    \"\"\"Make predictions using an ensemble of models from different folds\"\"\"\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "    test_dataset = TensorDataset(X_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Store all model predictions\n",
        "    all_model_preds = []\n",
        "\n",
        "    # Get predictions from each model\n",
        "    for i, model in enumerate(models):\n",
        "        model.eval()\n",
        "        model_preds = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (inputs,) in tqdm(test_loader, desc=f\"Predicting with model {i+1}\"):\n",
        "                inputs = inputs.to(device)\n",
        "                outputs = model(inputs)\n",
        "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "                model_preds.append(probs.cpu().numpy())\n",
        "\n",
        "        model_preds = np.concatenate(model_preds)\n",
        "        all_model_preds.append(model_preds)\n",
        "\n",
        "    # Average predictions from all models\n",
        "    ensemble_preds = np.mean(all_model_preds, axis=0)\n",
        "    return ensemble_preds\n",
        "\n",
        "# Get predictions using the ensemble (demonstration with validation data from first fold)\n",
        "if 'models' in cv_results:\n",
        "    print(\"Ensemble model ready for prediction.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324fc7c7",
      "metadata": {
        "id": "324fc7c7"
      },
      "source": [
        "## 9. Save the Final Ensemble Model\n",
        "\n",
        "Save the ensemble model and weights for future use or submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33030119",
      "metadata": {
        "id": "33030119"
      },
      "outputs": [],
      "source": [
        "# Save the ensemble model\n",
        "if 'models' in cv_results:\n",
        "    ensemble_save = {\n",
        "        'model_states': [model.state_dict() for model in cv_results['models']],\n",
        "        'model_architecture': 'BirdCNN',\n",
        "        'fold_aucs': cv_results['fold_aucs'],\n",
        "        'mean_auc': cv_results['mean_auc'],\n",
        "        'feature_params': {\n",
        "            'target_shape': (128, 256),\n",
        "            'sr': 32000,\n",
        "            'n_mels': 128,\n",
        "            'fmin': 500,\n",
        "            'fmax': 15000\n",
        "        },\n",
        "        'class_mapping': {idx: f\"class_{idx}\" for idx in range(len(np.unique(y)))}\n",
        "    }\n",
        "\n",
        "    model_save_path = os.path.join(MODEL_SAVE_DIR, 'bird_cnn_ensemble_balanced.pth')\n",
        "    torch.save(ensemble_save, model_save_path)\n",
        "    print(f\"Saved ensemble model to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44d44829",
      "metadata": {
        "id": "44d44829"
      },
      "source": [
        "## 10. Visualize Results by Class\n",
        "\n",
        "Analyze how our imbalanced data strategies performed on different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11be5d8c",
      "metadata": {
        "id": "11be5d8c"
      },
      "outputs": [],
      "source": [
        "# Analyze performance by class frequency\n",
        "if 'models' in cv_results and len(cv_results['predictions']) > 0:\n",
        "    # Choose a fold for evaluation (usually the fold with the highest AUC)\n",
        "    best_fold_idx = np.argmax(cv_results['fold_aucs'])\n",
        "    best_fold_preds = cv_results['predictions'][best_fold_idx]\n",
        "    best_fold_labels = cv_results['true_labels'][best_fold_idx]\n",
        "\n",
        "    # Calculate per-class metrics\n",
        "    from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "    # Convert probabilities to class predictions\n",
        "    predicted_classes = np.argmax(best_fold_preds, axis=1)\n",
        "\n",
        "    # Get class-wise precision, recall, and F1 scores\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        best_fold_labels, predicted_classes, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    # Get class frequencies in training data\n",
        "    class_counts = np.bincount(y)\n",
        "\n",
        "    # Create dataframe for visualization\n",
        "    import pandas as pd\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Class': [f\"class_{i}\" for i in range(len(precision))],\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'Support': support,\n",
        "        'Training Examples': [class_counts[i] if i < len(class_counts) else 0 for i in range(len(precision))]\n",
        "    })\n",
        "\n",
        "    # Sort by number of training examples (ascending)\n",
        "    metrics_df = metrics_df.sort_values('Training Examples')\n",
        "\n",
        "    # Plot relationship between class frequency and performance\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    # Scatter plot of F1 score vs. number of training examples\n",
        "    plt.scatter(metrics_df['Training Examples'], metrics_df['F1 Score'], alpha=0.6)\n",
        "    plt.xscale('log')  # Log scale for better visualization\n",
        "    plt.xlabel('Number of Training Examples (log scale)')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.title('F1 Score vs. Class Frequency')\n",
        "\n",
        "    # Add trend line\n",
        "    from scipy import stats\n",
        "    if len(metrics_df) > 1:  # Need at least 2 points for regression\n",
        "        x = np.log10(metrics_df['Training Examples'].replace(0, 1))  # Replace 0 with 1 for log\n",
        "        y = metrics_df['F1 Score']\n",
        "        slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
        "        x_pred = np.linspace(min(x), max(x), 100)\n",
        "        y_pred = slope * x_pred + intercept\n",
        "        plt.plot(10**x_pred, y_pred, 'r--', label=f'Trend line (r={r_value:.2f})')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # Display metrics for rare classes (10 or fewer examples)\n",
        "    rare_classes = metrics_df[metrics_df['Training Examples'] <= 10]\n",
        "    print(\"Performance on rare classes (≤10 examples):\")\n",
        "    print(rare_classes[['Class', 'Precision', 'Recall', 'F1 Score', 'Training Examples']])\n",
        "\n",
        "    # Display metrics for common classes (100+ examples)\n",
        "    common_classes = metrics_df[metrics_df['Training Examples'] > 100]\n",
        "    print(\"\\nPerformance on common classes (>100 examples):\")\n",
        "    print(common_classes[['Class', 'Precision', 'Recall', 'F1 Score', 'Training Examples']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948a52f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "class BirdCNN_Large(nn.Module):\n",
        "    \"\"\"A much larger CNN model to better utilize available GPU memory\"\"\"\n",
        "    def __init__(self, input_channels=1, num_classes=None):\n",
        "        super(BirdCNN_Large, self).__init__()\n",
        "\n",
        "        # Much larger feature extractor with more channels\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1 - 64->128 channels\n",
        "            nn.Conv2d(input_channels, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Block 2 - 128->256 channels\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # Block 3 - 256->512 channels\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.4),\n",
        "            \n",
        "            # Block 4 - 512->1024 channels (much more GPU-intensive)\n",
        "            nn.Conv2d(512, 768, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(768),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(768, 768, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(768),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.4),\n",
        "        )\n",
        "        \n",
        "        # Calculate size after convolutions (based on input spectrogram size)\n",
        "        self.feature_dims = 768 * 8 * 16  # Channels * Height * Width\n",
        "        \n",
        "        # Much larger fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(self.feature_dims, 2048),  # 4x larger than original\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Print model sizes to compare memory usage\n",
        "if torch.cuda.is_available():\n",
        "    num_classes = 206  # From your dataset\n",
        "    \n",
        "    # Create models\n",
        "    small_model = BirdCNN(input_channels=1, num_classes=num_classes).to(device)\n",
        "    large_model = BirdCNN_Large(input_channels=1, num_classes=num_classes).to(device)\n",
        "    \n",
        "    # Count parameters\n",
        "    small_params = sum(p.numel() for p in small_model.parameters())\n",
        "    large_params = sum(p.numel() for p in large_model.parameters())\n",
        "    \n",
        "    print(f\"Original BirdCNN parameters: {small_params:,}\")\n",
        "    print(f\"BirdCNN_Large parameters: {large_params:,}\")\n",
        "    print(f\"Size increase: {large_params/small_params:.1f}x more parameters\")\n",
        "    \n",
        "    # Free memory\n",
        "    del small_model\n",
        "    del large_model\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b0e9af7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the full training pipeline with much larger BirdCNN_Large model to utilize more GPU memory\n",
        "print(\"Starting training with BirdCNN_Large which will utilize much more GPU memory...\")\n",
        "\n",
        "# Set seed again for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# Run training with the larger model\n",
        "cv_results_large = train_with_imbalanced_strategies(\n",
        "    model_class=BirdCNN_Large,  # Using the larger CNN model\n",
        "    X=X,\n",
        "    y=y,\n",
        "    n_folds=3,  # Using fewer folds to make each fold use more memory\n",
        "    num_epochs=30,\n",
        "    patience=8\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2335072338ee45fdbb6c1d9206b2b616": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c89465d58e64730beb21c964ce6ab16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "584bfa84e4904340835484bac7bce695": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2df1701b30e4c2bb6b8f77ed9927604",
            "placeholder": "​",
            "style": "IPY_MODEL_4c89465d58e64730beb21c964ce6ab16",
            "value": "Epoch 1/30 [Train]:   0%"
          }
        },
        "5a9a9089e4014f42b94242672f5863f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6447a8783ab7460ebda8084b711e85e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a9a9089e4014f42b94242672f5863f4",
            "max": 372,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b45332615cd4eb194216a31f0c00b32",
            "value": 0
          }
        },
        "66b50f8a171b4e2eba1356c417d7bdf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b45332615cd4eb194216a31f0c00b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be64467c866840e4948bc2aef9d37ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2df1701b30e4c2bb6b8f77ed9927604": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f488547ff3c0495398050561ccc4607c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_584bfa84e4904340835484bac7bce695",
              "IPY_MODEL_6447a8783ab7460ebda8084b711e85e2",
              "IPY_MODEL_f7cb6328ad3b4198890e23d4917a8805"
            ],
            "layout": "IPY_MODEL_be64467c866840e4948bc2aef9d37ecc"
          }
        },
        "f7cb6328ad3b4198890e23d4917a8805": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b50f8a171b4e2eba1356c417d7bdf0",
            "placeholder": "​",
            "style": "IPY_MODEL_2335072338ee45fdbb6c1d9206b2b616",
            "value": " 0/372 [00:05&lt;?, ?it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
